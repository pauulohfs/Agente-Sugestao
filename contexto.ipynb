{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefe479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta dentro do contexto: Action:\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"O N8N (Node-Pipelines Next Generation) é um software de código aberto que permite criar e gerenciar pipelines automatizados para integração de diferentes aplicativos e serviços. Com o N8N, você pode criar triggers personalizados para disparar ações específicas em seu pipeline, como envio de emails ou atualização de bases de dados.\"\n",
      "}\n",
      "\n",
      "\n",
      "Pergunta fora do contexto: Essa questão não faz parte do curso.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.llms import Ollama\n",
    "import string\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"llama3\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Você é um tutor de curso online. Responda em pt-br APENAS com base no conteúdo fornecido. \n",
    "NÃO forneça informações externas. \n",
    "Se a pergunta não estiver no contexto, diga apenas: 'Essa questão não faz parte do curso.'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tools = []\n",
    "\n",
    "\n",
    "agente_tutor_especializado = initialize_agent(\n",
    "    tools = [],\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=5,\n",
    "    early_stopping_method=\"generate\"\n",
    ")\n",
    "\n",
    "# func para normalizar texto \n",
    "def normalize_text(texto):\n",
    "    texto = texto.lower()\n",
    "    for p in string.punctuation:\n",
    "        texto = texto.replace(p, \"\")\n",
    "    return set(texto.split())\n",
    "\n",
    "# func para verificar se a pergunta eh relevante para o contexto\n",
    "def pergunta_relevante(pergunta, contexto):\n",
    "    palavras_contexto = normalize_text(contexto)\n",
    "    palavras_pergunta = normalize_text(pergunta)\n",
    "    return len(palavras_contexto & palavras_pergunta) > 0\n",
    "\n",
    "# func de teste do tutor com filtragem\n",
    "def perguntar_ao_tutor(pergunta, contexto_aula):\n",
    "    if not pergunta_relevante(pergunta, contexto_aula):\n",
    "        return \"Essa questão não faz parte do curso.\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {system_prompt}\n",
    "\n",
    "    CONTEXTO:\n",
    "    {contexto_aula}\n",
    "\n",
    "    PERGUNTA:\n",
    "    {pergunta}\n",
    "    \"\"\"\n",
    "    return agente_tutor_especializado.run(prompt)\n",
    "\n",
    "# Contexto de exemplo\n",
    "contexto = \"Esta aula ensina sobre pipelines com N8N, incluindo triggers e automações básicas.\"\n",
    "\n",
    "# Testes\n",
    "resposta1 = perguntar_ao_tutor(\"Explique como pra q serve o N8N\", contexto)\n",
    "print(\"Pergunta dentro do contexto:\", resposta1)\n",
    "\n",
    "resposta2 = perguntar_ao_tutor(\"O que é MEM RAM?\", contexto)\n",
    "print(\"Pergunta fora do contexto:\", resposta2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
